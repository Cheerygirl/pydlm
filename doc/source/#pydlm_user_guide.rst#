.. currentmodule:: pydlm

This package implements the Bayesian dynamic linear model (DLM, Hurrison
and West, 1999) for time series analysis.
The DLM is built upon two layers. The first layer is
the fitting algorithm. DLM adopts a modified Kalman filter with a
unique discounting technique from
Hurrison and West (1999). Like the usual Kalman filter, it accepts a
transition matrix, a measurement matrix, an observation, a latent
state, an innovation and an error covariance matrix and return the
updated state and error covariance. These quantities will all be
supplied internally -- users are free from any annoying
calculations. Different from the usual Kalman filter, the modified
Kalman filter does not require the tuning of the two parameters: the
error covariance matrix and the observational variance, so the model
fitting is extremely efficient (could be up to 1000 times faster than
the EM algorithm), more details will be provided in the section of the
discounting technique.

The second layer of DLM is itsmodeling feature. Nicely summarized in
Hurrison and West (1999), most common models can be expressed in
one unified form -- canonical form, which is closely related to the
Jordan decomposition. Thanks to this keen observation, the DLM can
easily incorporate most modeling components and turn them into the
corresponding transition matrices and other quantities to be supplied
to the Kalman filter. Examples are trend, seasonality, holidays,
control variables and auto-regressive, which could appear
simultaneously in one model. Due to this nice property, users of this
package can construct models simply by "adding" some component into
the model as::

  >>> myDLM = dlm(data) + trend(2)

The modeling process is simple.

The purpose of the modeling is to better understand the time series
data and for to forecast into the future. So the key output from the
model are the filtered time series, smoothed time series and one-step
ahead prediction. We will cover this topic later in this section.

The advantage of `pydlm`:

    + flexibility in constructing complicated models

    + Extremely efficient model fitting with the discounting technique

    + user-specific adjustment on the adaptive property of the model

The disadvantage of `pydlm`:

    + only for Gaussian noise


Modeling functionality
======================

As discussed in the beginning, the modeling process is very simple
with `pydlm`, most modeling functions are integrated in the class
:class:`dlm`. Following is an example for constructing a dlm with
linear trend, 7-day seasonality and another control variable::

  >>> from pydlm import dlm, trend, seasonality, dynamic
  >>> data = [0] * 100 + [3] * 100
  >>> control = [0.5 for i in range(100) + [2.6 for i in
  range(100)]
  >>> myDLM = dlm(data) + trend(2) + seasonality(7) +
  dyanmic(control)

Now the variable `myDLM` contains the data and the modeling
information. It will construct the corresponding transition,
measurement, innovation, latent states and error covariance matrix
once model fitting is called. Modify an existing model is also
simple. User can brows the existing components of the model by::

  >>> myDLM.ls()

It will show all the existing components and their corresponding
names. Name can be specified when the component is added to the `dlm`,
for example::

  >>> myDLM = myDLM + seasonality(4, name = 'day4')
  >>> myDLM.ls()

We can also easily delete the unwanted component by using `delete`::

  >>> myDLM.delete('day4')


Modeling components
===================

There are four model components provided with this
package. :class:`trend` class is a model component for trending
behavior. The data might be increasing linearly or quadraticly, which
can all be captured by :class:`trend`. The degree argument specifics
the shape of the trend and the discounting factor will be explained
later in next section::

  >>> linearTrend = trend(degree = 2, discount = 0.99, name =
  'trend1')

The :class:`seasonality` class models the periodic behavior of the
data. Compared to the sine or cosine periodic curves,
:class:`seasonality` in this packages is more flexible, since it can
turn into any shapes, much broader than the triangular families::

  >>> weekPeriod = seasonality(period = 7, discount = 0.99, name =
  'week')

The :class:`dynamic` class offers the modeling ability to add any additional
observed time series as a controlled variable to the current one. For
example, when studying the stock price, the 'SP500' index could be a
good indicator for the modeling stock. A dynamic component need the
user to supply the necessary information of the control variable over
time::

  >>> SP500 = dynamic(features = SP500Index, discount = 0.99, name =
  'SP500')

The :class:`autoReg` class constructs the auto-regressive component on
the model, i.e., the direct linear or non-linear dependency between
the current observation and the previous days. User needs to specify
the number of days of the dependency::

  >>> AR3 = autoReg(degree = 3, discount = 0.99, name = 'ar3')

These four classes of model components offer abundant modeling
possiblities of the Bayesian dynamic linear model. Users can construct
very complicated models using these components, such as hourly, weekly or
monthly periodicy and holiday indicator and many other features.


Model fitting
=============

Entailed before, the fitting of the dlm is fulfilled by a modified
Kalman filter. Once the user finished constructing the model by adding
different components. the :class:`dlm` will compute all the necessary
quantities internally for using Kalman filter. So users can simply
call :func:`dlm.fitForwardFilter`, :func:`dlm.fitBackwardSmoother` or
even simply :func:`dlm.fit` to fit both forward filter and backward
smoother::

  >>> myDLM.fitForwardFilter()
  >>> myDLM.fitBackwardSmoother()
  >>> myDLM.fit()

The :func:`dlm.fitForwardFilter` is implemented in an online
manner. It keeps an internal count on the filtered dates and once new
data comes in, it will only filter the new data without touching the
existing results. In addition, the 